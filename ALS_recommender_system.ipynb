{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from copy import copy\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_to_list(series): #aggregate function for group_by\n",
    "\n",
    "    res = list(series)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sparse_tensor(df, batch_size=50, part=0.8): #makes two sparse tensors: train and test \n",
    "    \n",
    "    max_mov_id = df['movieId'].max()\n",
    "    max_user_id = df['userId'].max()\n",
    "    boundary = int(max_user_id * part)\n",
    "    \n",
    "    t_test = 0\n",
    "    t_train = 0\n",
    "    \n",
    "    df['movieId'] = df['movieId'] - 1\n",
    "    df['userId'] = df['userId'] - 1\n",
    "    \n",
    "    for i in range(0, max_user_id, batch_size):\n",
    "        \n",
    "        condition = (df.userId >= i) & (df.userId < i+batch_size)\n",
    "        new_df = df[condition].groupby(by='userId', as_index=False)[['movieId', 'rating']].agg(aggregate_to_list)\n",
    "\n",
    "        new_df['len'] = new_df['movieId'].apply(lambda x: len(x))\n",
    "        new_df['indexes'] = new_df['userId'].apply(lambda x: [x])\n",
    "        new_df['indexes'] = new_df['indexes'] * new_df['len']\n",
    "\n",
    "        idx = new_df[['movieId', 'indexes', 'rating']].sum()\n",
    "        indexes = np.asarray([np.asarray(idx['indexes'])-i, idx['movieId']])\n",
    "        \n",
    "        x_size = min(max_user_id - i, batch_size)\n",
    "        y_size = max_mov_id\n",
    "        \n",
    "        t_part = t.sparse_coo_tensor(indexes, np.asarray(idx['rating']), (x_size, y_size),\\\n",
    "                                     requires_grad=False, dtype=t.float32)\n",
    "\n",
    "        if i < boundary:\n",
    "            t_train = t_part if isinstance(t_train, int) else t.vstack((t_train, t_part))\n",
    "        elif i > boundary:\n",
    "            t_test = t_part if isinstance(t_test, int) else t.vstack((t_test, t_part))\n",
    "            \n",
    "    return t_train, t_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100831</th>\n",
       "      <td>610</td>\n",
       "      <td>166534</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1493848402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100832</th>\n",
       "      <td>610</td>\n",
       "      <td>168248</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1493850091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100833</th>\n",
       "      <td>610</td>\n",
       "      <td>168250</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1494273047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100834</th>\n",
       "      <td>610</td>\n",
       "      <td>168252</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1493846352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100835</th>\n",
       "      <td>610</td>\n",
       "      <td>170875</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1493846415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100836 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        userId  movieId  rating   timestamp\n",
       "0            1        1     4.0   964982703\n",
       "1            1        3     4.0   964981247\n",
       "2            1        6     4.0   964982224\n",
       "3            1       47     5.0   964983815\n",
       "4            1       50     5.0   964982931\n",
       "...        ...      ...     ...         ...\n",
       "100831     610   166534     4.0  1493848402\n",
       "100832     610   168248     5.0  1493850091\n",
       "100833     610   168250     5.0  1494273047\n",
       "100834     610   168252     5.0  1493846352\n",
       "100835     610   170875     3.0  1493846415\n",
       "\n",
       "[100836 rows x 4 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"ratings.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создание разреженных матриц происходит поэтапно. Из таблицы извлекается информация о части полизователей в количестве batch_size для них создается разреженная матрица и присоединяется к общей разреженной матрице. При грамотном выборе количества пользователей можно добиться ускорения обработки в два раза. Если общее число  пользователей было бы еще больше то ускоренее было бы еще более существенным. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 673 ms, sys: 123 ms, total: 797 ms\n",
      "Wall time: 801 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_csv(\"ratings.csv\")\n",
    "_ = make_sparse_tensor(df, batch_size=610)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 558 ms, sys: 34.7 ms, total: 593 ms\n",
      "Wall time: 581 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_csv(\"ratings.csv\")\n",
    "_ = make_sparse_tensor(df, batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 331 ms, sys: 70.9 ms, total: 401 ms\n",
      "Wall time: 456 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(indices=tensor([[    0,     0,     0,  ...,   539,   539,   539],\n",
       "                        [    0,     2,     5,  ..., 45721, 48384, 48515]]),\n",
       "        values=tensor([4., 4., 4.,  ..., 4., 4., 5.]),\n",
       "        size=(540, 193609), nnz=84327, layout=torch.sparse_coo),\n",
       " tensor(indices=tensor([[     0,      0,      0,  ...,     69,     69,     69],\n",
       "                        [     0,      6,      9,  ..., 168249, 168251, 170874]]),\n",
       "        values=tensor([3., 4., 4.,  ..., 5., 5., 3.]),\n",
       "        size=(70, 193609), nnz=16509, layout=torch.sparse_coo))"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_csv(\"ratings.csv\")\n",
    "train_factor_matrix, test_factor_matrix = make_sparse_tensor(df, batch_size=90)\n",
    "train_factor_matrix, test_factor_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSELoss(nn.Module): #Root mean square error loss\n",
    "    \n",
    "    def __init__(self, eps=1e-6):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "        self.eps = eps\n",
    "        \n",
    "        \n",
    "    def forward(self, prediction, y):\n",
    "        \n",
    "        self.zeros = t.zeros(prediction.shape)\n",
    "        prediction = t.where(y > 0, prediction, self.zeros)\n",
    "\n",
    "        num = t.where(y > 0)[0].shape[0]\n",
    "        loss = t.sqrt((prediction - y)**2 / (num + self.eps))\n",
    "\n",
    "        return loss.sum()/prediction.shape[0] # mean loss for exact batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class network_template(nn.Module): \n",
    "    \n",
    "    def __init__(self, layers):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.layers = layers\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ALS заключается в поочередной итеративной оптимизации матрицы характеристик пользователей U и матрицы характеристик фильмов V, в классе обучаются две нейрнных сети: одна получает наилучшее в среднеквадратичном смысле приближение матрицы факторов R оптимизируя матрицу U, вторая оптимизируя матрицу V. На каждой эпохе мы проходимся сначала по всем пользователям батчами размера u_batch затем по всем фильмам батчами размера v_batch. В список лоссов добавляется усредненные лоссы по всем батчам обоих моделей в одной эпохе (Возможно не совсем корректно усреднять лоссы по обеим моделям, но в целом динамику обучения это отражает. Такой способ подсчета лосса объясняет различие лоссов теста и трейна ведь в тесте лосс считается только по предсказанию U)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "class rec_als_model:\n",
    "    \n",
    "    def __init__(self, factor_train, X_test, d=48, u_batch=48, v_batch=4096, learning_rate=0.005):\n",
    "        \n",
    "        self.factor_train = factor_train.float()\n",
    "        self.X_test = X_test.float()\n",
    "        \n",
    "        self.x_size = factor_train.shape[0] # Data sizes\n",
    "        self.y_size = factor_train.shape[1]\n",
    "        self.d = d\n",
    "        \n",
    "        f_matr_copy_T = factor_train.clone().transpose_(1, 0)\n",
    "        \n",
    "        self.U_train_dataloader = DataLoader(factor_train, batch_size=u_batch, shuffle=False) # Dataloaders\n",
    "        self.V_train_dataloader = DataLoader(f_matr_copy_T, batch_size=v_batch, shuffle=False)\n",
    "        \n",
    "        self.RMSE_loss = RMSELoss()\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        self.U = t.rand((self.x_size, d), requires_grad=False, dtype=t.float32) + 1 #U, V initialization\n",
    "        self.V = t.rand((self.y_size, d), requires_grad=False, dtype=t.float32) + 1\n",
    "        \n",
    "        self.U_model = self.u_model_init()\n",
    "        self.V_model = self.v_model_init()\n",
    "        print('Models ready')\n",
    "        \n",
    "        self.u_optimizer = t.optim.Adam(self.U_model.parameters(), lr=self.learning_rate) # Optimizers\n",
    "        self.v_optimizer = t.optim.Adam(self.V_model.parameters(), lr=self.learning_rate)\n",
    "        print('Optimizers ready')\n",
    "\n",
    "        \n",
    "    def u_model_init(self):\n",
    "        \n",
    "        layers = nn.Sequential(nn.Linear(self.y_size, 2048),\n",
    "                               nn.ELU(),\n",
    "                               nn.Dropout(0.5),\n",
    "                               nn.Linear(2048, 1024),\n",
    "                               nn.ELU(),\n",
    "                               nn.Dropout(0.5),\n",
    "                               nn.Linear(1024, 256),\n",
    "                               nn.ELU(),\n",
    "                               nn.Dropout(0.5),\n",
    "                               nn.Linear(256, self.d))\n",
    "        \n",
    "        return network_template(layers)\n",
    "\n",
    "    \n",
    "    def v_model_init(self): \n",
    "        \n",
    "        layers = nn.Sequential(nn.Linear(self.x_size, self.x_size // 2),\n",
    "                               nn.ELU(),\n",
    "                               nn.Dropout(0.5),\n",
    "                               nn.Linear(self.x_size // 2, self.x_size // 2),\n",
    "                               nn.ELU(),\n",
    "                               nn.Dropout(0.5),\n",
    "                               nn.Linear(self.x_size // 2, self.x_size // 4),\n",
    "                               nn.ELU(),\n",
    "                               nn.Dropout(0.5),\n",
    "                               nn.Linear(self.x_size // 4, self.d))\n",
    "        \n",
    "        return network_template(layers)\n",
    "    \n",
    "    \n",
    "    def train(self, epochs=30): # Main training function\n",
    "        \n",
    "        losses_train = []\n",
    "        losses_test = []\n",
    "        \n",
    "        for i in range(epochs):\n",
    "            \n",
    "            losses = []\n",
    "            low_boundary = 0\n",
    "            high_boundary = self.U_train_dataloader.batch_size\n",
    "            \n",
    "            for f_matr_part in self.U_train_dataloader: # training U_model\n",
    "                \n",
    "                self.u_optimizer.zero_grad()\n",
    "                \n",
    "                dense_matr = f_matr_part.to_dense()\n",
    "                \n",
    "                prediction = self.U_model.forward(dense_matr.float())\n",
    "                self.U[low_boundary:high_boundary] = prediction\n",
    "                \n",
    "                loss = self.RMSE_loss.forward(prediction@(self.V.transpose(1, 0)), dense_matr)\n",
    "                loss.backward()\n",
    "                self.u_optimizer.step()\n",
    "                \n",
    "                low_boundary += self.U_train_dataloader.batch_size\n",
    "                high_boundary += self.U_train_dataloader.batch_size\n",
    "                \n",
    "                losses.append(float(loss.data))\n",
    "            \n",
    "            self.U = self.U.detach()\n",
    "            \n",
    "            low_boundary = 0\n",
    "            high_boundary = self.V_train_dataloader.batch_size\n",
    "            \n",
    "            for f_matr_part in self.V_train_dataloader: # training V_model\n",
    "                \n",
    "                self.v_optimizer.zero_grad()\n",
    "                \n",
    "                dense_matr = f_matr_part.to_dense()\n",
    "                \n",
    "                prediction = self.V_model.forward(dense_matr)\n",
    "                self.V[low_boundary:high_boundary] = prediction\n",
    "                \n",
    "                loss = self.RMSE_loss.forward(self.U@(prediction.transpose(1, 0)), dense_matr.transpose(1, 0))\n",
    "                loss.backward()\n",
    "                self.v_optimizer.step()\n",
    "                \n",
    "                low_boundary += self.V_train_dataloader.batch_size\n",
    "                high_boundary += self.V_train_dataloader.batch_size\n",
    "                \n",
    "                losses.append(float(loss.data))\n",
    "\n",
    "            self.V = self.V.detach()\n",
    "            \n",
    "            loss = np.mean(np.asarray(losses))\n",
    "            losses_train.append(loss)\n",
    "            \n",
    "            print('\\nEpoch {}\\nTrain loss = {}'.format(i, loss))\n",
    "            \n",
    "            test_loss = self.RMSE_loss.forward(self.forward(self.X_test.to_dense()), self.X_test.to_dense())\n",
    "            losses_test.append(float(test_loss.data))\n",
    "            print('Test loss = {}'.format(test_loss))\n",
    "            \n",
    "        return losses_train, losses_test\n",
    "            \n",
    "            \n",
    "    def forward(self, x): # Fills gaps in factor matrix (predicts unknown ratings)\n",
    "        \n",
    "        prediction = self.U_model.forward(x.float())\n",
    "        \n",
    "        return prediction@(self.V.transpose(1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models ready\n",
      "Optimizers ready\n"
     ]
    }
   ],
   "source": [
    "model = rec_als_model(train_factor_matrix, test_factor_matrix, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0\n",
      "Train loss = 4.594184825227907\n",
      "Test loss = 5.498933792114258\n",
      "\n",
      "Epoch 1\n",
      "Train loss = 1.2693915363866837\n",
      "Test loss = 8.580903053283691\n",
      "\n",
      "Epoch 2\n",
      "Train loss = 1.4715738965353617\n",
      "Test loss = 4.095565319061279\n",
      "\n",
      "Epoch 3\n",
      "Train loss = 0.8884141005498046\n",
      "Test loss = 3.634897232055664\n",
      "\n",
      "Epoch 4\n",
      "Train loss = 0.7977330410697808\n",
      "Test loss = 3.935516357421875\n",
      "\n",
      "Epoch 5\n",
      "Train loss = 0.7855826668596516\n",
      "Test loss = 2.562246799468994\n",
      "\n",
      "Epoch 6\n",
      "Train loss = 0.5972736026936522\n",
      "Test loss = 2.302893877029419\n",
      "\n",
      "Epoch 7\n",
      "Train loss = 0.6042672509657374\n",
      "Test loss = 2.2673022747039795\n",
      "\n",
      "Epoch 8\n",
      "Train loss = 0.5497232550677533\n",
      "Test loss = 2.6335771083831787\n",
      "\n",
      "Epoch 9\n",
      "Train loss = 0.5800445766304619\n",
      "Test loss = 2.39168643951416\n",
      "\n",
      "Epoch 10\n",
      "Train loss = 0.5430509688332676\n",
      "Test loss = 2.5040476322174072\n",
      "\n",
      "Epoch 11\n",
      "Train loss = 0.5586147422203794\n",
      "Test loss = 2.528024673461914\n",
      "\n",
      "Epoch 12\n",
      "Train loss = 0.5779523162908542\n",
      "Test loss = 2.678508996963501\n",
      "\n",
      "Epoch 13\n",
      "Train loss = 0.5913791176009302\n",
      "Test loss = 2.4293265342712402\n",
      "\n",
      "Epoch 14\n",
      "Train loss = 0.5022447311397021\n",
      "Test loss = 1.9772517681121826\n",
      "\n",
      "Epoch 15\n",
      "Train loss = 0.4516365344092871\n",
      "Test loss = 1.9611345529556274\n",
      "\n",
      "Epoch 16\n",
      "Train loss = 0.4412436129176058\n",
      "Test loss = 1.9092843532562256\n",
      "\n",
      "Epoch 17\n",
      "Train loss = 0.4346237317038079\n",
      "Test loss = 1.9167461395263672\n",
      "\n",
      "Epoch 18\n",
      "Train loss = 0.43172486844705416\n",
      "Test loss = 2.2234787940979004\n",
      "\n",
      "Epoch 19\n",
      "Train loss = 0.42499715071171523\n",
      "Test loss = 1.7519252300262451\n",
      "\n",
      "Epoch 20\n",
      "Train loss = 0.40404041522415357\n",
      "Test loss = 1.919763445854187\n",
      "\n",
      "Epoch 21\n",
      "Train loss = 0.40736691195440167\n",
      "Test loss = 1.9619121551513672\n",
      "\n",
      "Epoch 22\n",
      "Train loss = 0.40574442223102475\n",
      "Test loss = 2.097825288772583\n",
      "\n",
      "Epoch 23\n",
      "Train loss = 0.4323337796415823\n",
      "Test loss = 1.9094491004943848\n",
      "\n",
      "Epoch 24\n",
      "Train loss = 0.4092995350055086\n",
      "Test loss = 1.8033628463745117\n",
      "\n",
      "Epoch 25\n",
      "Train loss = 0.3924042758764699\n",
      "Test loss = 1.857513427734375\n",
      "\n",
      "Epoch 26\n",
      "Train loss = 0.3823689190263394\n",
      "Test loss = 1.9432770013809204\n",
      "\n",
      "Epoch 27\n",
      "Train loss = 0.39975770649228554\n",
      "Test loss = 2.0090816020965576\n",
      "\n",
      "Epoch 28\n",
      "Train loss = 0.4516305158147588\n",
      "Test loss = 2.12790846824646\n",
      "\n",
      "Epoch 29\n",
      "Train loss = 0.4438134211852836\n",
      "Test loss = 2.0515241622924805\n"
     ]
    }
   ],
   "source": [
    "losses_train, losses_test = model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_graphs(losses_train, losses_test):\n",
    "    \n",
    "    plt.figure(figsize=(7, 7))\n",
    "\n",
    "    plt.plot(losses_train, label=\"Train loss\", c='y')\n",
    "    plt.plot(losses_test, label=\"Test loss\", c='r')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Avarage RMSE loss')\n",
    "    plt.savefig(\"loss_graph.png\", dpi = 800)\n",
    "    \n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbEAAAGpCAYAAAADVQhHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deXycVdn/8c+ZZCZpk7ZJV1ra0krZCi2hlLIKIov4yCKbwMMmq4oiywMCCj8RQRFEBQW0liKIbCKboGwqIC6lBUoXtkJpoaXpRte0SSYz1++PM9OkbZZJMndmub/v12teM5nMck0C+fac+9zXcWaGiIhIIYrkugAREZGuUoiJiEjBUoiJiEjBUoiJiEjBUoiJiEjBKs11AS0NHDjQRo0alesyREQkT7z22msrzGxQW9/PqxAbNWoUM2bMyHUZIiKSJ5xzC9v7vqYTRUSkYCnERESkYCnERESkYOXVMTERkUISj8dZtGgR9fX1uS6l4JWXlzN8+HCi0WinnqcQExHpokWLFtGnTx9GjRqFcy7X5RQsM2PlypUsWrSI0aNHd+q5mk4UEemi+vp6BgwYoADrJuccAwYM6NKIViEmItINCrDs6OrPUSEmIiIFSyEmIlKgVq5cSU1NDTU1NWyzzTZsu+22m75ubGzM6DXOOuss3n333Yzfc8qUKVx88cVdLTnrtLBDRKRADRgwgJkzZwJw7bXXUllZyWWXXbbZY8wMMyMSaX3McvfddwdeZ5A0EhMRKTLvv/8+Y8eO5dRTT2XXXXdlyZIlnH/++UycOJFdd92V6667btNjDzjgAGbOnElTUxNVVVVceeWV7L777uy7774sW7as3ff58MMPOfjggxk/fjyHHXYYixYtAuDBBx9kt912Y/fdd+fggw8GYPbs2ey1117U1NQwfvx45s+fn5XPqpGYiEgWzJt3MevXz8zqa1ZW1rDDDr/o0nPfeecd7r33XiZOnAjAjTfeSP/+/WlqauLggw/mhBNOYOzYsZs9Z82aNRx00EHceOONXHrppUydOpUrr7yyzfe44IILOPfcczn11FOZPHkyF198MY888gg/+MEPePHFFxkyZAirV68G4I477uCyyy7jpJNOoqGhATPr0ufakkZiIiJFaPvtt98UYAAPPPAAEyZMYMKECbz99tu89dZbWz2nV69efPGLXwRgzz33ZMGCBe2+x7Rp0zj55JMBOOOMM/jnP/8JwP77788ZZ5zBlClTSCaTAOy3335cf/313HTTTXz88ceUl5dn42NqJCYikg1dHTEFpaKiYtPtefPmceutt/Lqq69SVVXFaaed1uo5WbFYbNPtkpISmpqauvTev/3tb5k2bRpPPfUUEyZM4I033uD0009n33335emnn+aII45g6tSpHHjggV16/ZY0Elu1KtcViIgEau3atfTp04e+ffuyZMkSnn322ay87j777MPDDz8MwH333bcplObPn88+++zDD3/4Q6qrq1m8eDHz589nzJgxXHTRRRx55JHMmjUrKzWEeyS2cCGMGQMvvAAHHZTrakREAjFhwgTGjh3LzjvvzHbbbcf++++flde9/fbbOfvss/nxj3/MkCFDNq10vOSSS/jwww8xMw4//HB22203rr/+eh544AGi0SjDhg3j2muvzUoNLlsH17Jh4sSJ1qObYr7wAhx2GEyZAuec03PvKyJF4e2332aXXXbJdRlFo7Wfp3PuNTOb2MZTQj6duGSJv06tnhERkcIS7hCrrfXXOi4mIlKQFGKgEBMRKVAKMdB0oohIgVKIgUZiIiIFSiEGGomJiBQohRhoJCYiBSkbW7EATJ06ldr038MtnHbaaTz++OPZKjnrwnuyc0MDfPqpv62RmIgUoEy2YsnE1KlTmTBhAttss022SwxceEdi6S0Gqqs1EhORonPPPfcwadIkampquOCCC0gmkzQ1NXH66aczbtw4dtttN2677TYeeughZs6cyUknndThCO65556jpqaGcePGcd5552167OWXX87YsWMZP348V1xxBdD6dixBCO9ILH2i8847w3/+A/X1kKWuyiISQhdfDDOzuxULNTXwi843Fp4zZw6PPfYY//73vyktLeX888/nwQcfZPvtt2fFihXMnj0bgNWrV1NVVcUvf/lLfvWrX1FTU9Pma27YsIGzzz6bl156ie23337T9isnnngif/nLX5g7dy7OuU1br7S2HUsQwjsSS8//plucaDQmIkXihRdeYPr06UycOJGamhpeeuklPvjgA8aMGcO7777Lt7/9bZ599ln69euX8Wu+/fbb7Ljjjmy//faA33rl5Zdfpn///kQiEc477zwee+yxTd3zW9uOJQjhHYm1FmJDh+auHhEpbF0YMQXFzDj77LP54Q9/uNX3Zs2axV//+lduv/12/vSnPzF58uRuvVc0GmXGjBk8//zz/PGPf+TOO+/kueeea3U7lurq6m69V2s0EttpJ3+txR0iUiQOPfRQHn74YVasWAH4VYwfffQRy5cvx8w48cQTue6663j99dcB6NOnD+vWrWv3NXfZZRfmzZvH/PnzAb/1ykEHHcS6detYu3YtRx55JD//+c954403gNa3YwlCuEdiAwfCoEH+a00nikiRGDduHN///vc59NBDSSaTRKNRfv3rX1NSUsI555yDmeGc4yc/+QkAZ511Fueeey69evXi1Vdf3WxzzLTevXtz1113cdxxx5FIJNh7770577zzWLZsGccddxwNDQ0kk0l+9rOfAa1vxxKE8G7FctxxMG8ePPKIX9xx331w6qk9894iUhS0FUt2aSuWzqithW228UvsQSMxEZECpBCrqvJf65iYiEjBCWeImTWHWCwGvXtrJCYiXZJPh2QKWVd/juEMsbVrYeNGH2LgR2MKMRHppPLyclauXKkg6yYzY+XKlZR3oeFEOFcnppfXp0OsulrTiSLSacOHD2fRokUsX74816UUvPLycoYPH97p5wUaYs65S4BzAQNmA2eZWX2Q75mRLUNMIzER6YJoNMro0aNzXUaoBTad6JzbFvg2MNHMdgNKgJODer9OSYdYukOHRmIiIgUp6GNipUAv51wp0Bv4JOD3y0xr04kaiYmIFJzAQszMFgM/BT4ClgBrzOy5LR/nnDvfOTfDOTejx+aVa2shGm0+R6yqSiMxEZECFOR0YjVwDDAaGAZUOOdO2/JxZjbZzCaa2cRB6RZQQUsvr3fOf11dDWvWQCLRM+8vIiJZEeR04qHAh2a23MziwKPAfgG+X+bSIZaWPuF57drc1CMiIl0SZIh9BOzjnOvtnHPAIcDbAb5f5rYMMbWeEhEpSEEeE5sGPAK8jl9eHwG6t3FNtixZ0vpITCEmIlJQAj1PzMy+D3w/yPfotEQCli9vfSSmxR0iIgUlfG2nli+HZFLTiSIiRSB8IbblOWKgTvYiIgUqvCGW7tYBGomJiBSo8IZYy5FYZSWUlGgkJiJSYMIbYkOGNN/nnJoAi4gUoHCGWN++fiPMlhRiIiIFJ5wh1nIqMU2d7EVECo5CLE2d7EVECk74QmzLbh1p6mQvIlJwwhdiGomJiBSNcIXYhg2+U317IzGznq9LRES6JFwhtnSpv25rJNbYCBs39mxNIiLSZeEKsdZOdE5T6ykRkYITzhBr2XIqTa2nREQKTjhDrL2RmEJMRKRghC/EIhEYNGjr72lPMRGRghO+EBs0yDf73ZKmE0VECk64QqytE51BCztERApQuEKsrROdQcfEREQKkEIsLRqFigqNxERECkh4Qsys/RADtZ4SESkw4QmxVasgHm8/xNQEWESkoIQnxNo7RyxNIzERkYISvhBrrVtHmkJMRKSghC/ENJ0oIlI0FGItaSQmIlJQwhNiS5ZAeTn07dv2Y6qqYN06aGrqubpERKTLwhNi6eX1zrX9mHTrqTVreqYmERHplvCFWHvUekpEpKAoxFpSE2ARkYKiEGtJISYiUlDCEWLxOKxYoelEEZEiE44QW7bMX2skJiJSVMIRYpl06wCNxERECky4QqyjkVhFBZSWaiQmIlIgwhFiS5b4645CzDm1nhIRKSDhCLH0SGzIkI4fq9ZTIiIFIzwhVl0NZWUdP1YjMRGRghGeEOtoKjFNIzERkYKhENuSQkxEpGAoxLak6UQRkYKhENtSeiRmFmxNIiLSbcUfYuvXQ11d50ZiTU2wYUOwdYmISLcVf4hl2q0jTa2nREQKRnhCrDMjMdBxMRGRAlD8IZZpt440jcRERApG8YdYZ0di6RDTSExEJO+FI8RKSmDAgMwen55O1EhMRCTvhSPEhgyBSIYfVdOJIiIFIxwhlulUIkC/fv5a04kiInlPIbal0lLo00cjMRGRAqAQa41aT4mIFITiDrFkEpYu7XyIqQmwiEhBKO4QW7kSEomuhZhGYiIiea+4Qyx9onOmLafSqqo0EhMRKQDFHWKdPdE5TdOJIiIFQSHWGi3sEBEpCAqx1lRX+y1c4vHs1yQiIllT/CFWUQGVlZ17Xrr11Jo12a9JRESypvhDrLOjMFDrKRGRAqEQa432FBMRKQgKsdZoJCYiUhAUYq3RnmIiIgWheEOsvt6PpLoznaiRmIhIXiveEFu61F93tlsHaDpRRKRAFG+IdfUcMYBevSAa1XSiiEieU4i1xjm1nhIRKQAKsbao9ZSISN4r/hAbPLhrz9dITEQk7xV3iA0c6I9tdYX2FBMRyXvFHWJdnUoE7SkmIlIAFGJt0XSiiEjeK94QW7Kk+yOx1avBLHs1iYhIVhVniJllZySWSPh9xUREJC8VZ4itWQMNDV3r1pGmTvYiInkv0BBzzlU55x5xzr3jnHvbObdvkO+3SXfPEQO1nhIRKQClAb/+rcAzZnaCcy4G9A74/bxshphGYiIieSuwEHPO9QMOBL4KYGaNQGNQ77eZbISYOtmLiOS9IKcTRwPLgbudc28456Y45yq2fJBz7nzn3Azn3Izly5dn5501EhMRCYUgQ6wUmADcaWZ7AHXAlVs+yMwmm9lEM5s4aNCg7Lxzba3v1JEOoq7QSExEJO8FGWKLgEVmNi319SP4UAteenm9c11/jX79/LVCTEQkbwUWYmZWC3zsnNspddchwFtBvd9munuOGEBJCfTtq+lEEZE8FvTqxAuBP6RWJs4Hzgr4/bwlS2C77br/Omo9JSKS1wINMTObCUwM8j1aVVsLe+/d/ddRJ3sRkbxWfB07mppg+fLuTyeCOtmLiOS54gux5ct978TutJxK00hMRCSvFV+IZeMcsTSNxERE8ppCrD0aiYmI5DWFWHuqqqCuDuLx7r+WiIhkXfGG2JAh3X8tdbIXEclrxRlifftC7yw0zNeeYiIiea34QmzJkuxMJYJGYiIiea74QiwbLafS1MleRCSvKcTao072IiJ5TSHWHo3ERETyWnGFWF0drFuXnW4doJGYiEieK64QW7rUX2drJNarF5SVKcRERPJUhyHmnDvROdcndftq59yjzrme2dyys7J5onNaVZWmE0VE8lQmI7FrzGydc+4A4FDgLuDOYMvqoiBCTHuKiYjkrUxCLJG6/hIw2cyeBmLBldQNQYWYRmIiInkpkxBb7Jz7DXAS8BfnXFmGz+t5hxwCd90FAwdm7zXVyV5EJG9lsrPzV4AjgJ+a2Wrn3FDg8mDL6qKddvKXbKquhvfey+5riohIVmQSYkOBp82swTn3OWA8cG+gVeUTjcRERPJWJtOCfwISzrkxwGRgBHB/oFXlk/QxMbNcVyIiIlvIJMSSZtYEHAf80swux4/OwqGqCpJJfxK1iIjklUxCLO6cOwU4A3gqdV80uJLyjDrZi4jkrUxC7CxgX+AGM/vQOTca+H2wZeUR9U8UEclbHYaYmb0FXAbMds7tBiwys58EXlm+UP9EEZG81eHqxNSKxHuABYADRjjnzjSzl4MtLU9oJCYikrcyWWJ/C3C4mb0L4JzbEXgA2DPIwvKGRmIiInkrk2Ni0XSAAZjZe4RxYYdGYiIieSeTkdgM59wU4L7U16cCM4IrKc/07QvOaSQmIpKHMgmxbwDfBL6d+vqfwB2BVZRvIhHo108hJiKShzoMMTNrAH6WuoST9hQTEclLbYaYc2420GavJTMbH0hF+Uh7iomI5KX2RmJH9lgV+U57iomI5KU2Q8zMFvZkIXmtqgreeSfXVYiIyBbyc3PLfKORmIhIXlKIZUJ7iomI5KU2Q8w517ed740Mppw8VV0NGzdCQ0OuKxERkRbaG4m9mL7hnPvbFt97PJBq8lW69ZSmFEVE8kp7IeZa3O7fzveKn/YUExHJS+2FmLVxu7Wvi5v6J4qI5KX2zhMb7Jy7FD/qSt8m9fWgwCvLJ+pkLyKSl9oLsd8CfVq5DTAlsIrykUZiIiJ5qb2TnX/Qk4XkNY3ERETyUntL7M9zzu2Quu2cc1Odc2ucc7Occ3v0XIl5QKsTRUTyUnsLOy4CFqRunwLsDnwGuBS4Ldiy8kx5ub9oJCYiklfaC7EmM4unbh8J3GtmK83sBaAi+NLyjFpPiYjknfZCLOmcG+qcKwcOAV5o8b1ewZaVh7Qdi4hI3mlvdeL/A2YAJcCTZjYXwDl3EDC/B2rLL+qfKCKSd9pbnfiUc247oI+ZtfzrPQM4KfDK8k11NSxZkusqRESkhfZ2dj6uxe3WHvJoEAXlraoqeOutXFchIiIttDed+AgwM3WBzfslGmELMS3sEBHJO+2F2HHAycB44AngATN7v0eqykdVVT7EkkmIaBs2EZF80OZfYzN73MxOBg4CPgBucc69klrYET7V1WAG69bluhIREUnJZEhRD6wB1gKVQHmgFXWTmWEWQJN9tZ4SEck77bWd+rxzbjLwGnAwcKuZ1ZjZsz1WXSctXnwnL79cRiIRwGhJe4qJiOSd9o6JvQDMAl4ByoAznHNnpL9pZt8OuLZOKympwCxOY+NSSkv7ZvfF1cleRCTvtBdiZ/VYFVkSiw0BIB5fBuyQ3RfXdKKISN5p72Tne9r6nnNuZDDldE80OhiAxsZl2X9xjcRERPJOuws7nHP7OudOcM4NTn093jl3P/CvHqmuk2KxdIgtzf6LayQmIpJ32lvYcTMwFTgeeNo5dz3wHDCNrM/VZUc0OghITydmWZ8+/vwwjcRERPJGe8fEvgTsYWb1zrlq4GNgNzNb0COVdUEkEqO0tDqY6cRIBPr100hMRCSPtDedWG9m9QCpBsDz8jnA0mKxIcTjAUwnglpPiYjkmfZGYp9xzj3Z4uvRLb82s6ODK6vrotHBwYzEQHuKiYjkmfZC7Jgtvr4lyEKyJRYbTF3dnGBeXHuKiYjklfaW2L/Uk4VkSzQ6hMbGvwXz4tXV8Mknwby2iIh0WtG1Y4/FBtPUtIpksjH7L66RmIhIXim6EEuf8ByPr8j+i2thh4hIXsk4xJxzvYMsJFvSracCO+G5vt5fREQk5zoMMefcfs65t4B3Ul/v7py7I/DKuijdtSOQE57VekpEJK9kMhL7OfAFYCWAmb0JHBhkUd3RI/0TdVxMRCQvZDSdaGYfb3FXIoBasiLw6UTQSExEJE+0d55Y2sfOuf0Ac85FgYuAt4Mtq+tKSvrgXFmw04kaiYmI5IVMRmJfB74JbAssBmpSX+cl5xyxWEBdO9TJXkQkr3Q4EjOzFcCpPVBL1gTWP1ELO0RE8kqHIeacu62Vu9cAM8zsieyX1H2+f2Jt9l9YIzERkbySyXRiOX4KcV7qMh4YDpzjnPtFgLV1WSw2OJhjYrEY9O4NH2+5zkVERHIhkxAbDxxsZr80s18ChwI7A8cChwdZXFf5/onLMLPsv/ixx8LvfgfvvJP91xYRkU7JJMSqgcoWX1cA/c0sATR09GTnXIlz7g3n3FNdrLHTYrHBmDXS1LQm+y9+yy1+NPa1r0Eymf3XFxGRjGUSYjcBM51zdzvnfge8AdzsnKsAXsjg+T2+JL+5f2IAU4pDhsDNN8PLL8Pdd2f/9UVEJGMdhpiZ3QXsBzwOPAYcYGZTzKzOzC5v77nOueHAl4Ap2Sg2U4Ge8Axw9tnw2c/C5ZfD0oDeQ0REOpRpA+B6YAmwChjjnMu07dQvgO8Abc67OefOd87NcM7NWL58eYYv275A+ycCRCLwm99AXR1cckkw7yEiIh3KpAHwucDLwLPAD1LX12bwvCOBZWb2WnuPM7PJZjbRzCYOGjQoo6I70tw/McBR0i67wFVXwQMPwDPPZO91zWDlyuy9nohIEctkJHYRsBew0MwOBvYAMjnbd3/gaOfcAuBB4PPOufu6WmhnRKM+DAPp2tHSVVfBTjvBBRfAhg3df71EAk47DUaM0AnVIiIZyCTE6s2sHsA5V2Zm7wA7dfQkM7vKzIab2SjgZODvZnZat6rNUCRSSmnpgOCmE9PKyvy04ocfwg9+0L3XSibhvPPg/vth40aYMSM7NYqIFLFMQmyRc64Kv7DjeefcE8DCYMvqvlhsSLDTiWkHHQTnnOOX3s+c2bXXMINvfcuvdkwfY5s2LXs1iogUqUxWJx5rZqvN7FrgGuAu4MudeRMze9HMjuxaiV0TWNeO1tx0EwwYAOef76cEO8MM/u//4M474Tvf8WG4007w6qvB1CoiUkTaDbHUicqbWlOY2Utm9qSZNQZfWvf4/ok9FGL9+8PPfw7Tp8Mdndz0+uqr/XO//W248UZwDiZN8iOxIDqOiIgUkXZDLNWV413n3Mgeqidremw6Me2UU+ALX4Dvfjfz3orXXw8/+pE/FvaLX/gAAx9iS5fCokXB1SsiUgQybTs11zn3N+fck+lL0IV1VzQ6mERiDclkh52xssM5PyWYSMCFF3b8+FtugWuugdNPh1//ujnAwIcYaEpRRKQDmezsfE3gVQQgfcJzY+NyysuH98ybjh4N114LV1wBjz3mmwW35vbb4bLL4CtfgalT/cnTLe2+O0SjPsSOPz7wskVEClUmm2K+1BOFZFu69VQ8vrTnQgz86sL77/ejsUMOgb59N//+XXf5lYjHHAP33QelrfwKysqgpkYjMRGRDmTSsWMf59x059x651yjcy7hnFvbE8V1R3PXjh5a3NH8xjB5MnzyCXzve5t/7777/PGvI46Ahx7yj23L3nv7c8U6u9pRRCREMjkm9ivgFPyGmL2Ac4HbgywqGwLvn9ieSZP8aOv22+G///X3PfIInHkmfO5z8OijfrTV0WusX699y0RE2pFRA2Azex8oMbOEmd0NHBFsWd0XjQbcyb4j118Pw4b5c8cefdSvXtx3X3jySejVq+Pna3GHiEiHMgmxDc65GH5PsZucc5dk+LycKimpIBLp1fPTiWl9+/qR2OzZfnFGTQ08/TRUVnb8XIAddoB+/RRiIiLtyCSMTk897ltAHTACyPslc845otEe7NrRmmOO8VOI++4Lzz7rQylTkQjstZfaT4mItCOTJfZ7Ak+b2Vr8ViwFo8dPeG5NevfnlueBZWrSJPjJT3xD4EymIEVEQiaTkdhRwHvOud875450zmUSfHmhR/sntsW5rgUY+BBLJOCNN7Jbk4hIkcikAfBZwBjgj/hVih8456YEXVg29Gj/xCBocYeISLsyGlWZWdw591fA8Mvsv4xfap/XYrEhxOPLMEviXN6vRdna0KEwfLhCTESkDZmc7PxF59zv8OeJHQ9MAbYJuK6siEYHY9ZEU1MB75I8aZJCTESkDZkMT87Ab4i5k5l91cz+YmZNAdeVFc39Ewt8SvGDD2DlylxXIiKSdzI5JnaKmT1uZg0AzrkDnHN537EDNu+fWLDSx8WmT89tHSIieSijA0XOuT2cczc75xYAPwQKohdSzvonZtPEiX51o6YURUS20ubCDufcjvjViKcAK4CHAGdmB/dQbd3WPBIr4BDr0wfGjlWIiYi0or2R2DvA54EjzewAM/slUFAt1aPRAYDL/QnP3ZVe3GGW60pERPJKeyF2HLAE+Idz7rfOuUOALp61mxvOlRCNDizs6UTwIbZ8OSxYkOtKRETySpshllrMcTKwM/AP4GJgsHPuTufc4T1VYHelzxUraDrpWUSkVZmsTqwzs/vN7ChgOPAGcEXglWWJ79pR4NOJ48b5/ccUYiIim+lUGwszW2Vmk83skKAKyra86J/YXdEoTJigEBMR2UIB9mLqnGh0SOEfEwM/pfjaa9BUEOeZi4j0iKIPsVhsMInEWhKJ+lyX0j2TJvktWebOzXUlIiJ5o+hDLH3Cc8FPKWpxh4jIVoo+xNInPBf8lOL220P//goxEZEWQhBi6ZFYga9QdE4d7UVEtlD0IVYU/RPTJk2COXOgri7XlYiI5IWiD7HmkViRhFgyCa+/nutKRETyQtGHWElJBZFIReGf8Ayw117+etq03NYhIpInij7EwI/GimI6cfBgGDVKx8VERFJCEmJF0D8xTYs7REQ2CUWIFUX/xLRJk2DhQlhaJJ9HRKQbQhFiRdE/MS190vP06bmtQ0QkD4QixHz/xOWYJXNdSvdNmACRiKYURUQISYj5ZfYJ4vFPc11K91VUwG67KcRERAhNiPnWU0U1pfjqq2CW60pERHIqFCHW3LWjSBZDTJoEq1bBBx/kuhIRkZwKRYgVVdcOgL339teaUhSRkAtFiEWjRdLJPm3sWOjdWyEmIqEXkhDrD0SKZzqxtBT23FPtp0Qk9EIRYs5FiEYHFc90IvjjYm+8AY2Nua5ERCRnQhFi4FcoFs10IvgQa2iA2bNzXYmISM6EKMQGF/7GmC2lO3fouJiIhFhoQsz3Tyyikdh228GgQQoxEQm10IRYUXWyB3BOHe1FJPRCE2LR6GASifUkEhtyXUr2TJoEb78Na9fmupLik0zCunW5rkJEOhCaEEuf8FxUU4qTJvnWU6+9lutKiocZPPYYjB8PQ4b42yKSt0IUYkXWPxFgr738db5NKTY1+T3PCokZPPus/4fBccdBPO5PKj/+eLjlFvWpFMlToQmxouufCDBgAGy/fX6FmBmcdhqMHl04f/xffhkOOgiOOAKWL4epU2HuXPjnP+GEE+Cyy+CCC3w4i0heCU2IFV3/xLS9986vELvlFnjoIdhlF//H/5xz8veE7OnT4Qtf8AE2bx786lfw7rtw1lm+K0qvXvDgg2IMYvMAAB/MSURBVHDllfDrX8NRR+n4o0ieCU2INY/EiizEJk2CRYvgk09yXQn87W9wxRV+9DJ7NlxzDdx9Nxx6qB/h5IvZs+HYY/3P7rXX4Oab/Y4A3/wmlJVt/thIBH78Y/jtb+H55+GAA+Cjj3JTt4hsJTQhVlLSi5KSPsU1nQiw337++jvf8cdxcmXhQjjpJNh5Zz8dF4nAddfB/ff7keKkSTBnTu7qAz/a+t//hd13h7//HX7wA5g/348Ye/du/7nnngt//av/nHvvrcU0InmiNNcF9KRodHDxTSfutZcPi//3//xo55FHoE+fnq1h48bmxRCPPbb5+59yij9ud8wxPnAfeAC+9KXsvn8iAZ9+6j//8uWwbFnz7fRl6VJ45RU/0rriCrj8cujfv3Pvc9hh8O9/+/oPPNAH9DHHZPeziEinhCrEiq5/Yto118CwYfC1r8HBB8PTT/vl4T3BzC96eP11+POfYccdt37MpEn++NPRR/vjSjffDJde6k/Y7qyGBnjiCbjvPnj/fR9Qn37qz+tqTXW172wyaBBcdJEPr2226fz7pu26K/z3v/6zHHss/Oxn/nW78llEpNtCFmKD2bjx/VyXEYxzzvF/nE880Y94nnkGdtgh+Pe980743e/g+9+HI49s+3HDh/vVfmee6afv5s71iyVisczeZ84cuOsu+P3vYeVKGDHCh2M6oFq7DBwI0WhWPuZmttkGXnwRTj8dLrnEh+kvfuEXg4hIzzKzvLnsueeeFqR33vmavfLK4EDfI+f++1+zgQP9Zdq0YN/rlVfMSkvNjjzSLJHI7DmJhNk115iB2Wc/a7ZsWduPXbPG7De/MZs0yT8+GjU78USzZ54xa2rKzmfojkTC7PLLfW3/8z9ma9fmuiKRogPMsHZyIzQLOyDdyX4FZolclxKcvfeGf/3LH5c6+GD4y1+CeZ9PPvGrEEeN8qOjSIb/KXW04MPMj9i++lUYOtRPkdbV+Wm7xYvh4Yf9sviSkiA+VedEInDTTX5E+eyz8NnP+lGiiPSYUIWYX2afJB4v8j80O+4I//mPXyl49NF+mXs2NTb6act16/xCjqqqzr/GKaf4k4zr65sXfNx0k6/5wAPh0Ufh1FP98afZs/203aBB2f0c2fK1r/njkHPn+jpFpMeEKsTSraeKcnHHloYM8cdtDjkEzj4brr8+e90zLrnEr9KbOhV2263rr5Ne8DFmjF/6fsUVMHiwD90lS2DyZD+yLIRFE1/4Alx1lR+VPvtsrqsRCY1QHYku2q4dbenTx68YPPdcv4Jx8WLflaI7U3G/+x3ccYdf5feVr3S/xvSCj0cf9acL7Lxz918zV773PfjjH/3IbM4cqKzMdUUiRS9UI7Gi7J/YkVgM7rmnuXXSCSf487q6YsYM+PrX/ejuRz/KXo0VFX6lXyEHGPhz0H77W39C9DXX5LoakVAIVYgVZSf7TDjnWyf98pf+HKtDD/XTeCtWZD7FuHy5P6F5yBDfT1DLyVt3wAH+vLlbb4Vp03JdjUjRC9VfotLSKpwrDccxsdZ861v+HKfTTvPHo8C3W9puO7/KsOV1+vaQIf5E4pNP9p0w/vUvf/6VtO3HP/b/WDj3XN+eKtNz4USk00IVYs5FiEYHhWs6cUsnnOCPPb3xhp/2WrgQFizw19Om+e4XLcViPrQ++cQfD9tzz1xUXVj69vUngR99tF9xefXVua5IpGiFKsTATymGbjpxS+mRVmvWr9882NK399vPd9uQzBx1lG+I/MMf+n84FPrxPpE8FboQi0YHh3c6MROVlb4/4K675rqSwnfrrfDcc3DeefDSS5mfEF4oFi70K1QvvNBPUYvkQJH9X9Ux37UjxNOJ0nOGDPGdRl55BX7zm1xXk121tX6B0Kuv+n3YamtzXZGEVOhCLBot0k72kp/OPNP/sb/iCr95aTH49FO/Lc2SJf70jfp6+L//y3VVElKhC7FYbDDJ5AYSibpclyJh4JwfhTU1+aX32eqakitr18IRR/gNRp94As44w5+DeP/98MILua5OQih0IRbKE54ltz7zGb/A489/9h09CtWGDX7Byuuv+89xyCH+/quu8hufXnCBH5VJ8Ugm/XHd447zO6JfeCE8/jisXp3ryjYJXYiFqn+i5I+LLoKJE/0fgS1PYygEjY1+leU//+n7Qx51VPP3yst9K7J58/wpBYXknXd8d5W//S3XleSXFSv85rU77uj7gr7yiu9rOnWq3wx2wADf1/S734W//z2n/3gJYYil+ydqJCY9qLQUpkzxW7UU2vGjpia/o8Bf/+qnRk85ZevHHH64P6XgRz/ym4Tmu+nT4fjjYexY3xz70EP9xrJ5NMLocWa+mcHpp/uept/5jt8x/v774eOP4fnnYdUqv/vE1Vf7DWdvvtmPyKur/c/wxhv9zzbRg9tdtbfZWHcuwAjgH8BbwFzgoo6eE/SmmGZmGzd+ZP/4B7Z48eTA30tkK1dd5TfRfP75XFeSmUTC7Ktf9TXfckv7j1282KxPH7PDDzdLJnumvs5IJs2ee87s85/3n6eqyuzqq80WLjS78kqzkhKzoUPNHnss15X2rLVrze64w2zcOP9z6dvX7FvfMpszJ7PnPvWU2SWXND8//bM99liz997rdnl0sClmkCE2FJiQut0HeA8Y295zeiLEEol6+8c/sAULrg/8vUS2snGj2Y47mo0ebVZXl+tq2pdMml14of8zce21mT3nttv84x96KNjaOqOpydezxx6+tmHDzH7606134n7tNbOaGv+YE080q63NTb09ZeZMs69/3ayy0n/mPfYwmzzZbN26rr9mba3Z/febnXOO/288Cz/DnIXYVm8ETwCHtfeYnggxM7OXX+5n7713YY+8l8hWXnzR/6/3f/+X60ra973v+TovvTTzkVVTk9mECX5Es2ZNsPV1ZONGs9/8xmzMGP85dtzRbMoUs/r6tp/T2Gh2ww1msZhZdbXZPffk56iys5JJs/nzze67z+yCC8zGj/c/k/JyP9KeNi1vP2dHIdYjHTucc6OAPYCt2no7584HzgcYOXJkT5RDLKZzxSSHDjoIzj8ffv5zf1xh4EDfb7FfP3+dvqS/rqzs3h5wXfGTn8ANN/huIz/9aeYbk5aU+C1/9t7bL5i49dZg62zN2rW+hp//3J+EPXEiPPIIfPnLHf8co1G/WOG44/wxsjPP9LuO/+Y30EN/n7KiocH3R/33v5svS5b471VWwj77+BPxzzwT+vfPba3d5HzQBfgGzlUCLwE3mNmj7T124sSJNmPGjEDrAXjjjc/iXJSamr8H/l4irVqzBj73OZg5M7PHV1b6UNt2Wxg/3l/GjfPX2f4jdMcdvgvHKaf4lYhdCdBvftMHyfTpMGFCdutLq6vzi0jmzYP33vPX8+bBm2/6HqCHHeZPMv/857u2O3gy6X8WV17pn3/jjfCNb+Rn+7BlyzYPrBkzfJCBP8Vjv/2aL7vt1vP/KOoG59xrZjaxze8HGWLOuSjwFPCsmf2so8f3VIjNmXM8Gza8w6RJcwN/L5F2JZP+D+7atT7Y1q5tvrT8es0af1mwAGbN8qsc09LBlg618eNhp526tgXMvff6f50fdRT86U9+ZNIVq1f7pscjR8J//tP1P5rJpF8G3zKk0qH1ySebP3boUNhhB7/i8Nxzs7fjwoIFfrfu557z+8VNmeJ/vrmUTPqR1lNP+Uv672Ys5kee6cDad1+//VIB6yjEAptOdM454C7g7UwCrCfFYkNYs+blXJch4v9Vn54+HD48s+eY+WmyWbP8ZfZsf/3CCxCP+8dEoz5ERo/29zU2+n+Zp69b3m55XV/vRy4PP9z1AAOoqvLTef/7v34q7oILOv8aL73kz697883m+wYN8kF12GH+escd/fWYMX60GoRRo+CZZ3zAX3JJ80m/Z53lA7OnrF/vf8dPPQVPP+3/G3DOTw1ef73/vU2Y4HcYD5HARmLOuQOAfwKzgWTq7u+a2V/aek5PjcQ+/PBaFi68jgMPbCQSCV0jfylW8Ti8+25zqM2a5c/vicX8H7aysubbrd1XVuZPYr3gguwEgpkPmxkz/Ggq0xHBwoVw+eW+K8jIkfC978Eee/iwqqrqfl3dUVsLl17qQz6R8KO900/3U6+DB2f//ebP94H11FPw4ov+Hxr9+vkTkI880rcAGzQo+++bR3I6ndhZPRViixffwbx532TffZdQVlbYQ22RvPbee36a84QT4A9/aP+xdXW+48dNN/kRxpVXwmWX+d3H882yZX7Bx+9/73fvLinxgXLGGX4z1PLyzr9mMulDa+ZMv0Ht00/D22/77+28M3zpSz649t+/e6PkApOz6cR8lm49FY8vU4iJBGnHHX0YXXcdnH12c7/FlszgwQd9h4hFi/yo5ic/gREjer7eTA0e7Kc6L7oI5s71YfaHP/iuJf36wYkn+kDbf//WF4Js3Ahz5vjASl9mzfJThuBD6qCD/LG4L33JT5dKq0I5Elu9+p/MnHkg48c/T//+hwb+fiKhVl/fvCJu1qzNj9m89poPgn/9yx/PufVWv3iiECUSfsrv97/3S/rr6vwxydNO86cczJ3rw+rNN/30ajJ1lKVPH6ip8cfaamr8ZddduzaaK0IaibVC/RNFelC6QfAXvuCnCq+5xh9b+t734O67/TGdKVPgq18tqKXfWykp8SPNQw6B22/33d7vvdefb5cOrJEjfUgdf3xzYI0alZ/L9gtEKEMsGlUne5EelW4QfMMNfiXkbbc1b6Z59dV+Cq6YVFT4psmnnupPBXj/fT8aLfATi/NRKOO/tLQfzkWJxxViIj3mZz/zKyFvuMEf75kzx3dBL7YA29KwYXDggQqwgIRyJOacIxodrI0xRXrSsGHw7LN+BHbwwbmuRopEKEMM1D9RJCf23TfXFUiRCeV0IvjFHZpOFBEpbKENMU0niogUvtCGWCw2hHh8Gfl0npyIiHROaEMsGh1MMllPIrE+16WIiEgXhTbE0ic8a0pRRKRwhTjEmvsniohIYQptiEWj6ZGYQkxEpFCFNsSaR2KaThQRKVShDbFodCDQ+ZFYY+NyksnGIEoSEZFOCm2IRSIxSkurMz4mZpbgo49+yn/+M5z33vt6wNWJiEgmQhtikG491fF0Yn39QmbOPIT58y8nFhtMbe09bNgwrwcqFBGR9oQ6xHzXjrZHYmZGbe3vmT59POvXv85OO93NnnvOIBIpY+HCG3qwUhERaU2oQ6y9/onx+EreeusrvPPOGVRWjmfixDcZOvSrxGJDGDbsGyxdeh8bNrzfwxWLiEhLoQ6xaLT16cSVK59h+vRxrFjxBJ/5zI3U1LxIr16jN31/xIjLiUSifPSRRmMiIrkU6hCLxQbT1PQpyWQcgERiA++99y1mz/4ipaXVTJgwjZEjr8C5zbdMLyvbhmHDvkFt7e/ZuPGDXJQuIiKEPMTSJzzH4ytYu3Y6M2bswSef3M7w4Zew556v0afPHm0+d8SI7xCJRHVsTEQkh0IdYukTnufPv5I33tiPZHIDu+/+AmPG/IySkvJ2n+tHY1+ntvZejcZERHIk5CHmR2JLl97LoEEnMnHiLKqrD8n4+c2jsR8FVaKIiLQj1CFWUbE7AwYcwy673M/YsfcTjVZ36vllZUMZOvR8li69l40b5wdUpYiItCXUIVZaWsm4cY8zZMgpXX6NkSOvAEo0GhMRyYFQh1g2lJUNY9iw81m69B42bvww1+WIiISKQiwL/GgswkcfaTQmItKTFGJZUFa2LcOGnU9t7e/YuHFBrssREQkNhViWjBih0ZiISE9TiGVJeflwhg49l9rau6mvX5jrckREQkEhlkUjR14JRFi48Me5LkVEJBQUYllUXj6CoUPPobZ2KvX1H+W6HBGRoqcQy7KRI68C4KOPNBoTEQmaQizL0qOxJUvu0mhMRCRgCrEANI/GbsxxJSIixU0hFoDy8pFss83ZLFkyhfr6j3NdjohI0VKIBWS77TQaExEJmkIsIOXl27HNNl9NjcYW5bocEZGipBAL0MiR3wWSzJv3Tdatm4mZ5bokEZGiUprrAopZr16jGDnyKhYuvJ6VK5+krGw7Bg78MgMHfpl+/Q4gEtGPX0SkO1w+jQ4mTpxoM2bMyHUZWdfYuIyVK//MihWP8+mnz2PWQGlpfwYMOIqBA79M//6HU1LSO9dliojkHefca2Y2sc3vK8R6VlPTelatepYVKx5n5cqnaGpaTSTSi+rqwxk48MsMGHAksdjAXJcpIpIXOgoxzWf1sNLSSgYNOp5Bg44nmYyzZs3LrFjxeCrUngAi9OmzJ6Wl1ZSU9CYSqaCkpKKd2xWUllbTr99+OFeS648nItKjFGI5FIlEqa4+hOrqQxgz5jbWr3+dFSseZ+3a/5JIrKWxcQmJxAaSyToSCX+BZKuv1bfvPuy0011UVIzt2Q8hIpJDCrE84ZyjT5896dNnzzYfY2aYNW4KtGRyA4lEHevXv8n8+d9hxowattvuakaOvJJIJNaD1YuI5IZCrIA453CujEikjGi0/6b7+/SZwIABR/L++xexYMH3Wb78j+y001T69t0rh9WKiARP54kViVhsEGPH3s9uuz1JPL6K11/fh/ffv4xEYkOuSxMRCYxCrMgMHHgUkybNZejQ81i06BamTx/PqlX/yHVZIiKBUIgVodLSfuy006/Zffe/A/Dmm5/n3Xe/RlPTmhxXJiKSXQqxIlZdfTB77TWLESMuY8mSKbz66lhWrPhzrssSEckaLewociUlvdl++5sZNOgrvPvuOcyZczSDB5/MwIHHkkw2Yta4xXVDq/eXlvajsrKGysoaevXaUS2ztuB/VnFKSipyXYpIqOgvUUj07bsXe+45g48+upGFC69n2bIH2328c1GcixGJxHAuRlPTKswaAYhEyqmoGL8p1Cora6ioGEdpaWWHdZgZTU2raGj4hMbGxTQ0LKah4RPi8eXEYttQXj6K8vLR9Oo1mmh0MM65rHz+tmpJJNbT1LSKpqZVxOOraGr6dNPtRGINicT6LS51rdy3HrM4AJWVezJw4DEMHHg0FRXjA61fRNR2KpQaGmppalq5WUg1X5elAmzzP77JZCMbNrzD+vUzN7s0Na1KPcLRq9cOm0KtvHwkjY3LaGhYvFlYNTZ+QjK5cauaSkr6kEis2+y+SKTXplDzl1H06pW+vR0QIZFYS1PTWhKJdanr5q+3/F5T0+pNgeUvqzFraucnFaGkpDLVGaVyi8vW9yWTcVateo61a/8LGOXloxgw4GgGDjyafv0OJBKJduv3JhJG6p0ogTEzGho+3irY6us/3PSYSKScWGxbysr8JRYb1srtYUQiZTQ1raehYSEbN35Iff2H1NcvSF37201NqztdYyRSQWlpX0pK+lJa2pfS0v5Eo9WUljZf2vq6pKRPl0ZSDQ21rFz5FCtXPsmqVc+TTNZTUtKPAQP+h4EDj6F//yMoLe3X6dcVCSOFmPS4eHw1jY2fEIsNpbS0KmtTavH46hbhtgDnIpSU9NkUUP665deVOe8nmUjU8emnz7Ny5ZOsXPln4vEVOBelqupzDBx4DH377k/v3jtTUlKe0zpF8pVCTCRPmCVYu/a/rFjxBCtWPMHGje+lvlNC7947UFExjoqK3TZd9+r1mZyHsEiuKcRE8tSGDe+zfv3r1NXNpq5uDuvXz6a+fj7g/5+MRHpRUbFri2AbR1nZCEpKehGJ9CIS6U1JSS8FnQQuHl9FY2Nt6ti5b33nj5+nj6MHt4BJW7GI5KnevcfQu/cY4Cub7ksk6qireysVbD7cVq78K7W1v2vzdZyLpkKtV2qbnvRtf928cCfaykKeza/9op4SnIsA/tqH5ObXm9/u+HVbvn8kUlFwp2g0Na0nHl9KY+NSGhtrAUc0OohodGDqUl0U/5hIJuNs3Pge69fPoq5uFuvXz6aubhYNDR+3+zz/uy1rEXA+7MaNe5LevXcMtObC+i9JpMiVlFTQt+9eWzVvbmxcTl3dbBoba0kmN5JIbCSZ3Ji6vWHT7a2/t45kMt7ivL94K+cGxjedItBzn7Mf0Wh/otEBqcU2zdfRaH9KSwds+n5JSSVmiU0XSGCWbHF76++BS40OHD5s/XXz/enbvt9DPP4pjY21mwVVy+tksq6DTxRJ1TuwxaVlyA2gpKQfpaXNl/TXuVi1amY0NtZSVze7RWDNYsOGtzedSuNclN69d6ZfvwOprBxPWdkIzOIkkw2p/3YaNl38+aVbft1IJBL8jvUKMZECEIsNIhb7fGCv77f5iZNMNgLJFqGw9e2W9/lLUyvB2FZoNpBIrCceX0lT06fE4yuJxz+lvn4+8finqVM2cnuIo7R0ALHYEGKxbejbd29isW02fR2NDiEWGwJAPL4idVm+1e0NG+YRj/+HeHwFkGj3/SKRXqlQ67tZwDVPG7ccWZe3cp+/P5HYQFPTahKJNanTSdakLv725vev3uxUl1hsWyorx9O//xeorBxPRcV4evfeqSC2dFKIiUhqm59Yzv9omSVoalqzWcglEutTU3Ulm6Yym7+ObPW95m56ScDwx/3Tt/31lrdLS6tSITUoqz8Df3L/6tRJ9Gs2XXygrG1xu+X31tLQ8EmL0XU9icRGzBo69d7OlVFaWtVi9FdFWdlwSkurKCnpR3n5yFTTgnFEowOy9pl7mkJMRPKGcyWpabn+HT+4ADjniEb9uYfdZZYkmazfaso4HXSRSO9NYeWnKcuy8Anyn0JMRKQA+PMie1NS0puomr9soi72IiJSsBRiIiJSsBRiIiJSsBRiIiJSsBRiIiJSsBRiIiJSsBRiIiJSsBRiIiJSsBRiIiJSsBRiIiJSsBRiIiJSsAINMefcEc65d51z7zvnrgzyvUREJHwCCzHn90S4HfgiMBY4xTk3Nqj3ExGR8AlyJDYJeN/M5pvfKvRB4JgA309EREImyBDbFvi4xdeLUvdtxjl3vnNuhnNuxvLlywMsR0REik3O9xMzs8nAZADn3HLn3MJuvuRAYEW3Cys8Yfzc+szhoM8cHq197u3ae0KQIbYYGNHi6+Gp+9pkZoO6+6bOuRlmNrG7r1Nowvi59ZnDQZ85PLryuYOcTpwO7OCcG+2ciwEnA08G+H4iIhIygY3EzKzJOfct4FmgBJhqZnODej8REQmfQI+JmdlfgL8E+R6tmNzD75cvwvi59ZnDQZ85PDr9uZ2ZBVGIiIhI4NR2SkRECpZCTEREClZRhVgYezU65xY452Y752Y652bkup6gOOemOueWOefmtLivv3PueefcvNR1dS5rzLY2PvO1zrnFqd/3TOfc/+Syxmxzzo1wzv3DOfeWc26uc+6i1P1F+7tu5zMX7e/aOVfunHvVOfdm6jP/IHX/aOfctNTf8IdSK9vbf61iOSaW6tX4HnAYvjvIdOAUM3srp4UFzDm3AJhoZkV9YqRz7kBgPXCvme2Wuu8m4FMzuzH1j5ZqM7sil3VmUxuf+VpgvZn9NJe1BcU5NxQYamavO+f6AK8BXwa+SpH+rtv5zF+hSH/XzjkHVJjZeudcFHgFuAi4FHjUzB50zv0aeNPM7mzvtYppJKZejUXMzF4GPt3i7mOAe1K378H/j1802vjMRc3MlpjZ66nb64C38e3qivZ33c5nLlrmrU99GU1dDPg88Ejq/ox+z8UUYhn1aixCBjznnHvNOXd+rovpYUPMbEnqdi0wJJfF9KBvOedmpaYbi2ZabUvOuVHAHsA0QvK73uIzQxH/rp1zJc65mcAy4HngA2C1mTWlHpLR3/BiCrGwOsDMJuC3vPlmagoqdMzPixfH3Hj77gS2B2qAJcAtuS0nGM65SuBPwMVmtrbl94r1d93KZy7q37WZJcysBt+ScBKwc1dep5hCrNO9GouBmS1OXS8DHsP/xxAWS1PHE9LHFZbluJ7AmdnS1P/8SeC3FOHvO3WM5E/AH8zs0dTdRf27bu0zh+F3DWBmq4F/APsCVc65dBOOjP6GF1OIha5Xo3OuInUgGOdcBXA4MKf9ZxWVJ4EzU7fPBJ7IYS09Iv2HPOVYiuz3nTrgfxfwtpn9rMW3ivZ33dZnLubftXNukHOuKnW7F35B3tv4MDsh9bCMfs9FszoRILUE9Rc092q8IcclBco59xn86At8C7H7i/UzO+ceAD6H36phKfB94HHgYWAksBD4ipkVzUKINj7z5/DTSwYsAL7W4lhRwXPOHQD8E5gNJFN3fxd/jKgof9ftfOZTKNLftXNuPH7hRgl+MPWwmV2X+pv2INAfeAM4zcwa2n2tYgoxEREJl2KaThQRkZBRiImISMFSiImISMFSiImISMFSiImISMFSiIkEyDmXaNGFfGY2d1dwzo1q2eFeJIxKO36IiHTDxlRrHREJgEZiIjmQ2gfuptRecK8658ak7h/lnPt7qunr35xzI1P3D3HOPZbaf+lN59x+qZcqcc79NrUn03Op7gcioaEQEwlWry2mE09q8b01ZjYO+BW+0wzAL4F7zGw88AfgttT9twEvmdnuwARgbur+HYDbzWxXYDVwfMCfRySvqGOHSICcc+vNrLKV+xcAnzez+anmr7VmNsA5twK/QWI8df8SMxvonFsODG/Zgie1bcfzZrZD6usrgKiZXR/8JxPJDxqJieSOtXG7M1r2lUug49wSMgoxkdw5qcX1f1K3/43fgQHgVHxjWIC/Ad+ATZsJ9uupIkXymf7VJhKsXqnda9OeMbP0Mvtq59ws/GjqlNR9FwJ3O+cuB5YDZ6XuvwiY7Jw7Bz/i+gZ+o0SRUNMxMZEcSB0Tm2hmK3Jdi0gh03SiiIgULI3ERESkYGkkJiIiBUshJiIiBUshJiIiBUshJiIiBUshJiIiBev/Ax1k+RCx/g1GAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw_graphs(losses_train, losses_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример выполнения функции forward для тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(test_factor_matrix, batch_size=1, shuffle=False)\n",
    "test_x = next(iter(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[2.8347, 3.8024, 3.3003,  ..., 3.1376, 3.1183, 3.1832]],\n",
       "        grad_fn=<SliceBackward>),\n",
       " tensor([[3., 0., 0.,  ..., 0., 0., 0.]]))"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = model.forward(test_x)\n",
    "prediction[:5], test_x.to_dense()[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраняем результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame({'Epoch': np.arange(30),\n",
    "                    'Train_loss': np.asarray(losses_train),\n",
    "                    'Test_loss': np.asarray(losses_test)})\n",
    "\n",
    "res['Test_loss'] = res['Test_loss'].apply(lambda x: float(x.data))\n",
    "res.to_csv('result.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
